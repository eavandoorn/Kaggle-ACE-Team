{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nCreated on Sat Jul 10 08:56:00 2017 GMT+1\\n\\n@author: Evert, based on Chris' feature processing\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Jul 10 08:56:00 2017 GMT+1\n",
    "\n",
    "@author: Evert, based on Chris' feature processing\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer, Imputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, ShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "\n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "#Read data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "print(train.head())\n",
    "print(\"\\n\")\n",
    "print(test.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% preprocessing input data\n",
    "imputer = Imputer(strategy = \"median\")\n",
    "encoder = LabelBinarizer()\n",
    "stdScaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# refill NA data\n",
    "def refillData(data, colName, **kwargs):\n",
    "    if \"replaceValue\" in kwargs:\n",
    "        data[colName].fillna(kwargs[\"replaceValue\"], inplace = True)\n",
    "    else:\n",
    "        data[colName].fillna(data[colName].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label categorical data\n",
    "def binaryEncoding(data, colName, encoder):\n",
    "    data[colName] = encoder.fit_transform(data[colName])\n",
    "\n",
    "#refillData(train, \"Age\", replaceValue = 0)\n",
    "#refillData(train, \"Embarked\", replaceValue = \"unknown\")\n",
    "\n",
    "binaryEncoding(train, \"Sex\", encoder)\n",
    "binaryEncoding(test, \"Sex\", encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop non-numeric columns\n",
    "columns2drop = [\"PassengerId\", \"Survived\", \"Name\", \"Ticket\", \"Cabin\", \"SibSp\", \"Parch\", \"Embarked\", \"Fare\" ]\n",
    "train_num = train.drop(columns2drop, axis = 1)\n",
    "columns2drop = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\", \"SibSp\", \"Parch\", \"Embarked\", \"Fare\" ]\n",
    "test_num = test.drop(columns2drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# refill the missing numeric data with median\n",
    "imputer.fit(train_num)\n",
    "X = imputer.transform(train_num)\n",
    "X_test = imputer.transform(test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scale age\n",
    "# print(X)\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "X[:,2] = scale(X[:,2])\n",
    "X_test[:,2]= scale(X_test[:,2])\n",
    "\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## encode the categorical data into one-hot data\n",
    "#embark = encoder.fit_transform(train[\"Embarked\"])\n",
    "\n",
    "# concatenate the data together\n",
    "#X = np.c_[X, embark]\n",
    "y = train[\"Survived\"]\n",
    "#X[:,-1] = stdScaler.fit_transform(X[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.812570145903\n",
      "{'std_train_score': array([ 0.        ,  0.        ,  0.02666578,  0.0103778 ,  0.        ,\n",
      "        0.00396805,  0.00619829,  0.0079361 ,  0.00901368]), 'rank_test_score': array([7, 7, 6, 4, 7, 5, 2, 1, 3]), 'mean_score_time': array([ 0.00300002,  0.00866667,  0.00666666,  0.00433334,  0.00833321,\n",
      "        0.00400003,  0.00233324,  0.00533334,  0.00300002]), 'std_test_score': array([ 0.        ,  0.        ,  0.06472669,  0.04928058,  0.        ,\n",
      "        0.03089989,  0.01239659,  0.01802736,  0.02598392]), 'split1_train_score': array([ 0.61616162,  0.61616162,  0.75252525,  0.76936027,  0.61616162,\n",
      "        0.73232323,  0.77946128,  0.80976431,  0.80808081]), 'split0_test_score': array([ 0.61616162,  0.61616162,  0.60942761,  0.69360269,  0.61616162,\n",
      "        0.68350168,  0.78787879,  0.76767677,  0.75757576]), 'mean_test_score': array([ 0.61616162,  0.61616162,  0.69135802,  0.76318743,  0.61616162,\n",
      "        0.72502806,  0.78675645,  0.79124579,  0.78226712]), 'split2_train_score': array([ 0.61616162,  0.61616162,  0.69360269,  0.79461279,  0.61616162,\n",
      "        0.73232323,  0.79461279,  0.82659933,  0.79461279]), 'param_C': masked_array(data = [0.001 0.001 0.001 0.01 0.01 0.01 100 100 100],\n",
      "             mask = [False False False False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'split0_train_score': array([ 0.61616162,  0.61616162,  0.6986532 ,  0.77946128,  0.61616162,\n",
      "        0.72390572,  0.78619529,  0.82659933,  0.81649832]), 'params': ({'kernel': 'linear', 'C': 0.001}, {'kernel': 'rbf', 'C': 0.001}, {'kernel': 'poly', 'C': 0.001}, {'kernel': 'linear', 'C': 0.01}, {'kernel': 'rbf', 'C': 0.01}, {'kernel': 'poly', 'C': 0.01}, {'kernel': 'linear', 'C': 100}, {'kernel': 'rbf', 'C': 100}, {'kernel': 'poly', 'C': 100}), 'std_fit_time': array([  1.24721369e-03,   1.08422487e-02,   2.05484912e-03,\n",
      "         1.63297214e-03,   3.09120493e-03,   4.92163852e-03,\n",
      "         8.64898172e+00,   4.76398290e-02,   3.69589436e+01]), 'std_score_time': array([  0.00000000e+00,   4.71314168e-04,   1.24731989e-03,\n",
      "         1.24723493e-03,   4.71370354e-04,   1.12391596e-07,\n",
      "         4.71482745e-04,   4.71426560e-04,   0.00000000e+00]), 'split2_test_score': array([ 0.61616162,  0.61616162,  0.6969697 ,  0.79461279,  0.61616162,\n",
      "        0.73400673,  0.77104377,  0.79461279,  0.77104377]), 'mean_train_score': array([ 0.61616162,  0.61616162,  0.71492705,  0.78114478,  0.61616162,\n",
      "        0.7295174 ,  0.78675645,  0.82098765,  0.80639731]), 'mean_fit_time': array([  0.04966672,   0.10066668,   0.07966661,   0.06199996,\n",
      "         0.10233339,   0.0666666 ,  31.3876667 ,   1.01733335,  44.03366661]), 'param_kernel': masked_array(data = ['linear' 'rbf' 'poly' 'linear' 'rbf' 'poly' 'linear' 'rbf' 'poly'],\n",
      "             mask = [False False False False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'split1_test_score': array([ 0.61616162,  0.61616162,  0.76767677,  0.8013468 ,  0.61616162,\n",
      "        0.75757576,  0.8013468 ,  0.81144781,  0.81818182])}\n",
      "0.791245791246\n"
     ]
    }
   ],
   "source": [
    "# Select optimal hyperparameters for support vector \n",
    "#\n",
    "#\n",
    "# WARNING: May take some time to complete\n",
    "# Consider cutting back on the number of cross-validations, \n",
    "# currently 3, by specifying 'cv = 1' or 'cv = 2' in the GridSearchCv call.\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly'), 'C':[.001, .01, 100]}\n",
    "svClf = SVC(C = 1, kernel = 'rbf', probability = True)\n",
    "clf = GridSearchCV(svClf, parameters)\n",
    "clf.fit(X, y)\n",
    "print(clf.score(X, y))\n",
    "print(clf.cv_results_)\n",
    "print(clf.best_score_)\n",
    "\n",
    "# Note that optimal model is automatically fitted to clf after this command. \n",
    "\n",
    "# Or, short-cutting the procedure:\n",
    "# clf = SVC(C = 100, kernel = 'rbf', probability = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n_jobs', 'verbose', 'estimator__gamma', 'estimator__decision_function_shape', 'estimator__probability', 'param_grid', 'cv', 'scoring', 'estimator__cache_size', 'estimator__verbose', 'pre_dispatch', 'estimator__kernel', 'fit_params', 'estimator__max_iter', 'refit', 'iid', 'estimator__shrinking', 'estimator__degree', 'estimator__class_weight', 'estimator__C', 'estimator__random_state', 'return_train_score', 'estimator', 'estimator__coef0', 'error_score', 'estimator__tol']\n"
     ]
    }
   ],
   "source": [
    "# Plot validation curve\n",
    "#\n",
    "# Validation curve shows the model's predictive utility at various levels of the chosen parameter\n",
    "# Here, parameter is coefficient penalty C\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "print(clf.get_params().keys())\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    clf, X, y, param_name=\"estimator__C\", param_range=[0.1, 10, 100],\n",
    "    cv=3, scoring=\"accuracy\", n_jobs=1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with SVM\")\n",
    "plt.xlabel(\"$\\Penalty \\(C\\)\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.812570145903\n",
      "     Survived  predicted\n",
      "0           0          0\n",
      "1           1          1\n",
      "2           1          1\n",
      "3           1          1\n",
      "4           0          0\n",
      "5           0          0\n",
      "6           0          0\n",
      "7           0          0\n",
      "8           1          1\n",
      "9           1          1\n",
      "10          1          0\n",
      "11          1          1\n",
      "12          0          0\n",
      "13          0          0\n",
      "14          0          0\n",
      "15          1          1\n",
      "16          0          0\n",
      "17          1          0\n",
      "18          0          1\n",
      "19          1          1\n",
      "20          0          0\n",
      "21          1          0\n",
      "22          1          0\n",
      "23          1          0\n",
      "24          0          0\n",
      "25          1          0\n",
      "26          0          0\n",
      "27          0          0\n",
      "28          1          1\n",
      "29          0          0\n",
      "..        ...        ...\n",
      "861         0          0\n",
      "862         1          1\n",
      "863         0          1\n",
      "864         0          0\n",
      "865         1          1\n",
      "866         1          1\n",
      "867         0          0\n",
      "868         0          0\n",
      "869         1          0\n",
      "870         0          0\n",
      "871         1          1\n",
      "872         0          0\n",
      "873         0          0\n",
      "874         1          1\n",
      "875         1          0\n",
      "876         0          0\n",
      "877         0          0\n",
      "878         0          0\n",
      "879         1          1\n",
      "880         1          1\n",
      "881         0          0\n",
      "882         0          1\n",
      "883         0          0\n",
      "884         0          0\n",
      "885         0          0\n",
      "886         0          0\n",
      "887         1          1\n",
      "888         0          1\n",
      "889         1          0\n",
      "890         0          0\n",
      "\n",
      "[891 rows x 2 columns]\n",
      "('True positives: ', 226L, '\\n')\n",
      "('True negatives: ', 498L, '\\n')\n",
      "('False positives: ', 51L, '\\n')\n",
      "('False negatives: ', 116L, '\\n')\n"
     ]
    }
   ],
   "source": [
    "#Show confusion matrix\n",
    "clf.fit(X, y)\n",
    "print(clf.score(X, y))\n",
    "\n",
    "prediction = clf.predict(X)\n",
    "compare = pd.concat([pd.Series(y), pd.Series(prediction, name = 'predicted')], axis = 1)\n",
    "print(compare)\n",
    "\n",
    "compare['tp'] = 0\n",
    "compare.loc[((compare['Survived']==1)&(compare['predicted']==1)), 'tp']=1\n",
    "compare['tn'] = 0\n",
    "compare.loc[((compare['Survived']==0)&(compare['predicted']==0)), 'tn']=1\n",
    "compare['fp'] = 0\n",
    "compare.loc[((compare['Survived']==0)&(compare['predicted']==1)), 'fp']=1\n",
    "compare['fn'] = 0\n",
    "compare.loc[((compare['Survived']==1)&(compare['predicted']==0)), 'fn']=1\n",
    "\n",
    "print(\"True positives: \", compare['tp'].sum(), \"\\n\")\n",
    "print(\"True negatives: \", compare['tn'].sum(), \"\\n\")\n",
    "print(\"False positives: \", compare['fp'].sum(), \"\\n\")\n",
    "print(\"False negatives: \", compare['fn'].sum(), \"\\n\")\n",
    "\n",
    "# We can crossref the 'False' label scores with potential features that may increase predictive utility\n",
    "# Patterns will tell us something of the potential for additional predictive validity of these features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot ROC curve and area under curve\n",
    "#\n",
    "# ROC curve visualizes the predictive utility of our model\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_pred = clf.predict(X)\n",
    "fpr, tpr, thresholds = roc_curve(y, y_pred, pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b',\n",
    "label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.2])\n",
    "plt.ylim([-0.1,1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% classifier testing\n",
    "\n",
    "rforestClf = RandomForestClassifier(n_estimators = 5, max_features = 3, bootstrap = False)\n",
    "rforestClf.fit(X, y)\n",
    "cross_val_score(rforestClf, X, y, cv = 3, scoring= \"accuracy\")\n",
    "\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "        rforestClf, X, y, cv=cv, n_jobs=4, train_sizes=np.linspace(.1, 1.0, 5))\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "print \"test score: {0:.2f}%, training score {1:.2f}%\".format(test_scores_mean.mean()*100, train_scores_mean.mean()*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% classifier testing\n",
    "\n",
    "rforestClf = RandomForestClassifier(n_estimators = 5, max_features = 3, bootstrap = False)\n",
    "rforestClf.fit(X2, y)\n",
    "cross_val_score(rforestClf, X2, y, cv = 3, scoring= \"accuracy\")\n",
    "\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "        rforestClf, X2, y, cv=cv, n_jobs=4, train_sizes=np.linspace(.1, 1.0, 5))\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "print \"test score: {0:.2f}%, training score {1:.2f}%\".format(test_scores_mean.mean()*100, train_scores_mean.mean()*100)\n",
    "\n",
    "test_scores_mean2 = np.mean(test_scores, axis = 0)\n",
    "y2 = y\n",
    "fpr2, tpr2, thresholds1 = roc_curve(y2, test_scores_mean2, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% classifier testing\n",
    "\n",
    "rforestClf = RandomForestClassifier(n_estimators = 5, max_features = 3, bootstrap = False)\n",
    "rforestClf.fit(X3, y)\n",
    "cross_val_score(rforestClf, X3, y, cv = 3, scoring= \"accuracy\")\n",
    "\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "        rforestClf, X3, y, cv=cv, n_jobs=4, train_sizes=np.linspace(.1, 1.0, 5))\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "print \"test score: {0:.2f}%, training score {1:.2f}%\".format(test_scores_mean.mean()*100, train_scores_mean.mean()*100)\n",
    "\n",
    "test_scores_mean3 = np.mean(test_scores, axis = 0)\n",
    "y3 = y\n",
    "fpr3, tpr3, thresholds3 = roc_curve(y3, test_scores_mean3, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"random forest classifier\")\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#%%\n",
    "f, ax = plt.subplots()\n",
    "n_features = X.shape[1]\n",
    "width = 0.5\n",
    "ax.bar(range(n_features), rforestClf.feature_importances_, width)\n",
    "ax.grid()\n",
    "ax.set_xticks(range(n_features))\n",
    "ax.set_xticklabels(train_num.columns)\n",
    "ax.set_ylabel(' Feature Importance')\n",
    "f.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#%% test score for test sets\n",
    "#\n",
    "#binaryEncoding(test, \"Sex\", encoder)\n",
    "#\n",
    "## drop non-numeric columns\n",
    "#test_num = test.drop(columns2drop, axis = 1)\n",
    "#\n",
    "## refill the  missing numeric data with median\n",
    "#imputer.fit(test_num)\n",
    "#Xtest = imputer.transform(test_num)\n",
    "#\n",
    "#ytest = test[\"Survived\"]\n",
    "#\n",
    "#y_pred = rforestClf.predict(Xtest)\n",
    "#test_score = accuracy_score(ytest, y_pred)\n",
    "#\n",
    "#print \"test_score = {:.3f}%\".format(test_score*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
